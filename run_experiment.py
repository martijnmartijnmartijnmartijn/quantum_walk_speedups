"""
@author: Martijn Brehm (m.a.brehm@uva.nl)
@date: 15/01/2024

This script generates SAT instances, solves them, saves several interesting
features computed during the solving, and then computes (upper-bounds on) the time and query complexity needed by several quantum algorihtm to solve that
instance. The script requires input parameters
- k (integer)
- n1 (integer)
- n2 (integer)
- reps (integer)
- mode (one of "random_sat" (default), "random_unsat", "community_sat", "community_unsat")
- solver ("BT" (default) if the base backtracking solver should be used,
          "CDCL" if the modern CDCL solver should be used)
- paths (0 (default) if the paths should not be saved, 1 if they should be).
- beta (0 (default), 1)
- T (1 (default))

The script then generates "k"-SAT instances from class "mode" in "n1" up
to and including "n2" variables, "reps" for each number of variables. It solves these instances and then saves the following
data into the file data/solver-mode-k-n1-n2-reps.csv (where "paths" is
appeneded after reps and just before .csv if set to its non-default value):
- the number of variables
- the index of the instance (i.e. between 0 and "reps")
- the number of seconds the sat solver needed to solve this instance.
- the size of the backtracking tree.
- the depth of the backtracking tree.
- the number of satisfying assignments in the backtracking tree.
- the total number of satisfying assignments.
- the size of the backtracking tree upon finding the first solution.
- the depth of the backtracking tree upon finding the first solution.
- the number of queries needed by the detection algorithm given perfect upper-bound W and upper-bound R=n.
- the number of queries needed by the detection algorithm given perfect upper-bound W and upper-bound R=1.
- the number of queries needed by the binary search algorithm given perfect upper-bound W and upper-bound R=n
- the number of queries needed by the binary search algorithm that estimates upper-bound W and is given upper-bound R=n.
- if paths is set, all the paths are listed as bistrings, separated by commas.
If the CDCL solver is used then only the first three values are saved.

Example 1: the command "python3 run_experiment.py 3 10 40 50 random_sat"
generates 50 uniformly random satisfiable
3-SAT instances in 10, 11, ..., 40 variables, solves them using the backtracking algorithm with the efficient predicate while not keeping the paths, and writes all the relevant data to "data/BT-random_sat_3-10-40-50.csv".

Example 2: "python3 run_experiment.py 3 10 40 50 random_sat BT 1"
would do the same, except it would keep the paths and save the data to "data/BT-random_sat_3-10-40-50-paths.csv"

Example 3: "python3 run_experiment.py 3 10 40 50 community_sat" would generate
the same number of instances in the same number of variables as above, except
it would generate satisfiable instances with community structure and save them
to "data/BT-community_sat_3-10-40-50.csv"

Example 4: "python3 run_experiment.py 3 10 40 50 random_unsat CDCL 0 0 " would
generate the same number of instances in the same number of variables as above,
but they would be uniformly random and unsatisfiable, but they are solved by a
modern CDCL solver, and the data would be saved to
"data/CDCL-random_unsat-10-40-50.csv"

To plot the complexity of the classical and quantum algorithms on these instances, you can call python3 plot_queries_over_n.py with the data files generated by this script. For instance, we can use the files generated by examples 1 and 3 to compare the performance on random intances and instances with community structure: "python3 plot_queries_over_n.py data/BT-random_sat_3-10-40-50.csv data/BT-community_sat_3-10-40-50.csv"
"""
from sys import argv
from math import ceil, sqrt, log
from random import randint
from csv import reader, writer
from cnfgen.families.randomformulas import RandomKCNF as RandomKCNF
from subprocess import check_output
from pysat.solvers import Solver
from pysat.formula import CNF
from sympy import binomial

def dpll(path, k=3, paths=False):
    """
    Takes a SAT instance encoded in the dimacs file at "path" and solves it
    using a the sat solver in the program cpp_solver (or cpp_solver_no_paths
    if paths is set to False).

    We simply pass on the list of values output by this program, which are:
    - the size of the backtracking tree.
    - the depth of the backtracking tree.
    - the number of satisfying assignments in the backtracking tree.
    - the total number of satisfying assignments.
    - the size of the backtracking tree upon finding the first solution.
    - the depth of the backtracking tree upon finding the first solution.
    - the number of seconds the sat solver needed to solve this instance.
    - a list of bitstrings denoting the paths to each of the satisfying
     assignments, i.e. 001 means the first variable was set to F, the second
     to F and the third to T.

     The paths are including only if "paths" is set to True. These are output
     first by the sat solver program, with each bitstring on a separate line.
     The other values then follow on the last line, separated by comma's.

     Example:
        dpll("uf50-218/uf50-01.cnf")
        print_solution(dpll("uf50-218/uf50-01.cnf"))
    """
    command = "./solvers/solver"
    if paths:
        command += "_print_paths"
    output = check_output([command, "{}".format(path), str(k)], encoding="utf8").split('\n')
    result = [int(float(val)) for val in output[-1].split(',')]
    if paths:
        result += [output[:-1]]
    return result

def get_n_reps(ep, r):
    """
    Given the error probability ep of an algorithm, and a number of repetitions
    r. Say you want r consecutive runs of the algorithm to succeed with the
    success probability 1-ep of the original algorithm. This requires
    amplifying the success probability of the original algorithm to p such that
    p^r = 1-ep. This function calculates the number of repetitions r' that you
    need to do of your original 1-ep algorithm so that a majority vote of the
    r' outcomes amplifies the success probability to at least this p.
    """
    target_ep = (1-ep)**(1/r)
    exp = lambda n : (1-p)**n * \
            sum([binomial(n, i) * (p/(1-p))**i for i in range(1 + floor(n/2))])
    n = 1
    while ep > target_ep:
        n += 2
        ep = exp(n)
    return n

def q_bt(C, n_reps, R, W):
    """
    Given constants C and n, and upper-bounds R on effective resistance and W
    on the sum of weights in the graph, computes the number of queries Belovs'
    detection algorithm makes.
    """
    return n_reps * (2**(log(sqrt((1 + C**2) * (1 + C * W * R)), 2))) - n_reps

def q_bt_b_search(C, n_reps, R, W, tree_depth, sol_depth):
    """
    Given constants C and n, upper-bounds R on effective resistance and W
    on the sum of weights in the graph, the depth of the backtracking tree, and
    the depth of the first solution that the heuristic walks towards, computes
    the number of queries that the binary search algorithm using Belovs'
    detection algorithm makes.
    """
    return q_bt(C, n_reps, R, W) * sol_depth * get_n_reps(DELTA, tree_depth)

def q_bt_b_search_est_W(C, n_reps, R, W, tree_depth):
    """
    Given constants C and n, upper-bounds R on effective resistance and W
    on the sum of weights in the graph and the depth of the backtracking tree, computes an upper-bound on the number of queries that the binary search algorithm using Belovs' detection algorithm makes, which determines by itself an upper-bound on W.
    """
    return sum([q_bt(C, n_reps, R, 2**w) * get_n_reps(DELTA, tree_depth) * tree_depth for w in range(ceil(log(W, 2)))])

def q_grover(L, t):
    """
    Given list size L and number of marked elements t, computes the expected
    number of queries to the list needed by Grover's algorithm.
    """
    if t == 0:
        return 9.2 * ceil(log(1/DELTA, 3)) * sqrt(L)
    F = 2.0344 if L/4 <= t else 9/4 * L/sqrt((L - t)*t) + ceil(log(L/sqrt((L - t)*t), 6/5)) - 3
    return F * (1 + 1/(1 - F/(9.2 * sqrt(L))))

# The ratio clauses/variables where a phase transition occurs for uniformly random 3-SAT, 4-SAT, ..., 13-SAT instances.
ratios = (4.267,9.931,21.117,43.37,87.79,176.54,354.01,708.92,1418.71,2838.28,
          5677.41,11355.67,22712.20)

# Indices into data from .csv files.
N_VARS = 0
REP = 1
TIME = 2
SIZE = 3
DEPTH = 4
N_SOLUTIONS = 5
N_SOLUTIONS_TOTAL = 6
FIRST_SOL_SIZE = 7
FIRST_SOL_DEPTH = 8

# Constants used throughout calculations.
DELTA = 0.001
C = 3.73538045831806
n_reps = 23

# Read input arguments.
k = int(argv[1])
n1 = int(argv[2])
n2 = int(argv[3])
reps = int(argv[4])
mode = argv[5] if len(argv) > 5 else "random_sat"
solver = argv[6] if len(argv) > 6 else "BT"
paths = int(argv[7]) if len(argv) > 7 else False
beta = argv[8] if len(argv) > 8 else 0
T = argv[9] if len(argv) > 9 else 1

# Set-up the file that we write the solutions to.
append_to_end = "-paths" if paths else ""
temp = mode + "_" + str(beta) + "_" + str(T) if "community" in mode else mode
filename = "data/" + solver + "-" + temp + "-" + str(k) + "-" + str(n1) + "-" + str(n2) + "-" + str(reps) + append_to_end + ".csv"
outfile = open(filename, "w", newline='')
csvwriter = writer(outfile, delimiter=',')
csvwriter.writerow(["n", "repetition", "CPU_time_s", "nodes", "depth", "n_solutions_tree", "n_total_solutions", "nodes_first_solution", "depth_first_solution", "q_detect_opt_W_R=n", "q_detect_opt_W_R=1", "q_binary_search_opt_W_R=n", "q_binary_search_est_W_R=n"])

# For all number of variables and repetitions:
for n in range(n1, n2+1):
    print("n={}: ".format(n), end='')
    m = int(ceil(ratios[k-3] * n))
    total_generated = 0
    sat_count = 0
    r = 0

    # Generate instance according to specified generation mode.
    while r < reps:
        if "community" in mode:
            formula = check_output(["./generators-IJCAI17/psc3.1", "-n " + str(n), "-m " + str(m), "-K " + str(k), "-T " + str(T), "-b " + str(beta), "-s " + str(randint(0,100000))], encoding="utf8")
        elif "random" in mode:
            formula = RandomKCNF(k, n, m).to_dimacs()

        # Solve instance according to specified solver.
        tempfile = open("temp.dimacs", "w")
        tempfile.write(formula)
        tempfile.close()
        output = [n, r]
        if solver == "BT":
            output += dpll("temp.dimacs", k=k, paths=paths)
            solve = output[N_SOLUTIONS] > 0
            sol_depth = output[FIRST_SOL_DEPTH] if output[FIRST_SOL_DEPTH] > 0 else n
            output += [q_bt(C, n_reps, n, output[SIZE]),
                q_bt(C, n_reps, 1, output[SIZE]),
                q_bt_b_search(C, n_reps, n, output[SIZE], n, sol_depth),
                q_bt_b_search_est_W(C, n_reps, n, output[SIZE], n),
                q_grover(2**n, output[N_SOLUTIONS_TOTAL])]

        elif solver == "CDCL":
            s = Solver(bootstrap_with=CNF(from_string=formula), use_timer=True)
            solve = s.solve()
            stats = s.accum_stats()
            output += [s.time_accum(), stats["decisions"]+stats["propagations"]]

        # These two counters are just for my understanding of community struc.
        total_generated += 1
        sat_count = sat_count + 1 if solve else sat_count

        # Checks if the random instance was of the correct type.
        if ("unsat" in mode and solve) or ("_sat" in mode and not solve):
            continue
        csvwriter.writerow(output)
        r += 1

    # Also print is just for m.e
    print("  fraction satisfiable: {} ({}/{})".format(sat_count/total_generated, sat_count, total_generated))

outfile.close()
print("\nSaved data to {}".format(filename))
